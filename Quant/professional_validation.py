#!/usr/bin/env python3
"""
VALIDACI√ìN PROFESIONAL COMPLETA - L√ìPEZ DE PRADO (VERSI√ìN CORREGIDA)
==================================================

Este m√≥dulo realiza una validaci√≥n exhaustiva y profesional de TODOS los m√≥dulos
de "Advances in Financial Machine Learning" implementados:

üìä M√ìDULOS A VALIDAR:
1. data_structures - Todas las funciones de estructuras de datos
2. util - Todas las utilidades y herramientas
3. labeling - Todos los m√©todos de etiquetado
4. multi_product - Funciones multi-producto

üéØ OBJETIVOS:
- Validar cada funci√≥n con datos reales
- Generar m√©tricas estad√≠sticas profesionales
- Crear visualizaciones comprehensivas
- Detectar errores y problemas
- Asegurar calidad de producci√≥n

üìà FUENTES DE DATOS:
- Archivos Excel (WTI, Bitcoin, Gold, etc.)
- yfinance (m√∫ltiples activos)
- Tiingo API (datos profesionales)
- Datasets ML internos

Autor: Sistema de Validaci√≥n Profesional
Fecha: Julio 2025
Basado en: "Advances in Financial Machine Learning" - L√≥pez de Prado
"""

import os
import sys
import importlib
import importlib.util
import warnings
import time
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union

# An√°lisis de datos
import pandas as pd
import numpy as np
import yfinance as yf
import requests

# Visualizaci√≥n
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# Configuraci√≥n
warnings.filterwarnings('ignore')
plt.rcParams['figure.figsize'] = (16, 10)
plt.rcParams['font.size'] = 10

# APIs
TIINGO_API_KEY = "9eaef8cdc8d497afb83a312d53be56633ec1bf51"
TIINGO_HEADERS = {'Content-Type': 'application/json'}

print("üöÄ SISTEMA DE VALIDACI√ìN PROFESIONAL - L√ìPEZ DE PRADO")
print("=" * 80)
print(f"üìÖ Iniciado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)


def configure_ml_paths():
    """Configurar rutas para importaciones de Machine Learning"""
    base_path = os.path.dirname(__file__)
    ml_path = os.path.join(base_path, 'Machine Learning')
    
    paths = [
        ml_path,
        os.path.join(ml_path, 'data_structures'),
        os.path.join(ml_path, 'util'),
        os.path.join(ml_path, 'labeling'),
        os.path.join(ml_path, 'multi_product'),
        os.path.join(ml_path, 'datasets')
    ]
    
    for path in paths:
        if os.path.exists(path) and path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"‚úÖ Configuradas {len(paths)} rutas de ML")

# Configurar rutas
configure_ml_paths()


def safe_import_module(module_name: str, file_path: str = None) -> Optional[Any]:
    """
    Importar m√≥dulo de manera segura sin errores
    
    Args:
        module_name: Nombre del m√≥dulo
        file_path: Ruta completa al archivo (opcional)
    
    Returns:
        M√≥dulo importado o None si falla
    """
    try:
        if file_path and os.path.exists(file_path):
            spec = importlib.util.spec_from_file_location(module_name, file_path)
            if spec and spec.loader:
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                return module
        else:
            return importlib.import_module(module_name)
    except Exception as e:
        print(f"‚ö†Ô∏è No se pudo importar {module_name}: {str(e)[:100]}...")
        return None


class LopezDePradoValidator:
    """
    Validador profesional completo para todos los m√≥dulos de L√≥pez de Prado
    """
    
    def __init__(self):
        """Inicializar el validador"""
        self.start_time = time.time()
        
        # Resultados por categor√≠a
        self.results = {
            'data_structures': {},
            'util': {},
            'labeling': {},
            'multi_product': {}
        }
        
        # Datos y m√≥dulos
        self.data_sources = {}
        self.modules = {}
        self.errors = []
        self.warnings = []
        
        # Estad√≠sticas
        self.stats = {
            'total_functions': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'data_points': 0
        }
        
        print("üéØ Validador Profesional Inicializado")
        print(f"   üìã Categor√≠as: {len(self.results)}")
        print(f"   üïê Tiempo de inicio: {datetime.now().strftime('%H:%M:%S')}")
    
    def load_all_modules(self) -> None:
        """Cargar todos los m√≥dulos de Machine Learning"""
        print("\nüì¶ CARGANDO M√ìDULOS DE MACHINE LEARNING...")
        print("-" * 50)
        
        ml_base = os.path.join(os.path.dirname(__file__), 'Machine Learning')
        
        # 1. Data Structures
        self._load_data_structures(ml_base)
        
        # 2. Util Modules
        self._load_util_modules(ml_base)
        
        # 3. Labeling Modules
        self._load_labeling_modules(ml_base)
        
        # 4. Multi-Product Modules
        self._load_multiproduct_modules(ml_base)
        
        # Resumen
        total_modules = sum(len(modules) for modules in self.modules.values())
        print(f"\nüìä RESUMEN DE M√ìDULOS CARGADOS:")
        for category, modules in self.modules.items():
            print(f"   {category:20}: {len(modules):2d} m√≥dulos")
        print(f"   {'TOTAL':20}: {total_modules:2d} m√≥dulos")
    
    def _load_data_structures(self, ml_base: str) -> None:
        """Cargar m√≥dulos de data_structures"""
        print("   üìä Data Structures...")
        
        ds_path = os.path.join(ml_base, 'data_structures')
        ds_modules = {}
        
        files = [
            'standard_data_structures',
            'imbalance_data_structures', 
            'run_data_structures',
            'time_data_structures',
            'base_bars'
        ]
        
        for file in files:
            file_path = os.path.join(ds_path, f'{file}.py')
            module = safe_import_module(file, file_path)
            if module:
                ds_modules[file] = module
                print(f"      ‚úÖ {file}")
            else:
                print(f"      ‚ùå {file}")
        
        self.modules['data_structures'] = ds_modules
    
    def _load_util_modules(self, ml_base: str) -> None:
        """Cargar m√≥dulos de util"""
        print("   ‚öôÔ∏è Util Modules...")
        
        util_path = os.path.join(ml_base, 'util')
        util_modules = {}
        
        files = [
            'volume_classifier',
            'fast_ewma',
            'volatility',
            'misc',
            'generate_dataset',
            'multiprocess'
        ]
        
        for file in files:
            file_path = os.path.join(util_path, f'{file}.py')
            module = safe_import_module(file, file_path)
            if module:
                util_modules[file] = module
                print(f"      ‚úÖ {file}")
            else:
                print(f"      ‚ùå {file}")
        
        self.modules['util'] = util_modules
    
    def _load_labeling_modules(self, ml_base: str) -> None:
        """Cargar m√≥dulos de labeling"""
        print("   üè∑Ô∏è Labeling Modules...")
        
        labeling_path = os.path.join(ml_base, 'labeling')
        labeling_modules = {}
        
        files = [
            'labeling',
            'trend_scanning',
            'bull_bear',
            'excess_over_mean',
            'excess_over_median',
            'fixed_time_horizon',
            'raw_return',
            'tail_sets',
            'return_vs_benchmark',
            'matrix_flags'
        ]
        
        for file in files:
            file_path = os.path.join(labeling_path, f'{file}.py')
            module = safe_import_module(file, file_path)
            if module:
                labeling_modules[file] = module
                print(f"      ‚úÖ {file}")
            else:
                print(f"      ‚ùå {file}")
        
        self.modules['labeling'] = labeling_modules
    
    def _load_multiproduct_modules(self, ml_base: str) -> None:
        """Cargar m√≥dulos de multi_product"""
        print("   üîÑ Multi-Product Modules...")
        
        mp_path = os.path.join(ml_base, 'multi_product')
        mp_modules = {}
        
        files = [
            'etf_trick',
            'futures_roll'
        ]
        
        for file in files:
            file_path = os.path.join(mp_path, f'{file}.py')
            module = safe_import_module(file, file_path)
            if module:
                mp_modules[file] = module
                print(f"      ‚úÖ {file}")
            else:
                print(f"      ‚ùå {file}")
        
        self.modules['multi_product'] = mp_modules
    
    def load_comprehensive_data(self) -> None:
        """Cargar datos de todas las fuentes disponibles"""
        print("\nüìä CARGANDO DATOS COMPREHENSIVOS...")
        print("-" * 50)
        
        # 1. Datos Excel locales
        self._load_excel_data()
        
        # 2. Datos de yfinance
        self._load_yfinance_data()
        
        # 3. Datos de Tiingo API
        self._load_tiingo_data()
        
        # 4. Datasets ML internos
        self._load_ml_datasets()
        
        # Resumen
        total_datasets = len(self.data_sources)
        total_points = sum(len(df) for df in self.data_sources.values())
        self.stats['data_points'] = total_points
        
        print(f"\nüìà RESUMEN DE DATOS:")
        print(f"   Datasets cargados: {total_datasets}")
        print(f"   Puntos de datos: {total_points:,}")
        print(f"   Memoria estimada: {total_points * 8 / 1024 / 1024:.1f} MB")
    
    def _load_excel_data(self) -> None:
        """Cargar datos de archivos Excel"""
        print("   üìà Cargando datos Excel...")
        
        excel_files = [
            'WTI Crude Oil Daily.xlsx',
            'WTI Crude Oil 1 Min.xlsx', 
            'Bitcoin Daily.xlsx',
            'Bitcoin 1 Min.xlsx',
            'Gold Daily.xlsx',
            'Gold 1 Min.xlsx',
            'Silver Daily.xlsx',
            'Silver 1 Min.xlsx',
            'Euro Daily.xlsx',
            'Euro 1 Min.xlsx'
        ]
        
        for file in excel_files:
            file_path = os.path.join('Datos', file)
            if os.path.exists(file_path):
                try:
                    # Cargar saltando encabezados (row 33)
                    df = pd.read_excel(file_path, skiprows=32)
                    df = df.dropna(how='all')
                    
                    if len(df) > 0:
                        # Mejorar detecci√≥n de columna de fecha
                        date_col = self._find_date_column_enhanced(df)
                        if date_col:
                            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            df = df.dropna(subset=[date_col])
                            df.set_index(date_col, inplace=True)
                            df = df.sort_index()
                            
                            # Limpiar nombres de columnas
                            df.columns = [str(col).strip().lower().replace(' ', '_') for col in df.columns]
                            
                            # Guardar
                            key = file.replace('.xlsx', '').replace(' ', '_').lower()
                            self.data_sources[key] = df
                            print(f"      ‚úÖ {file}: {len(df):,} registros")
                        else:
                            # Debug: mostrar las primeras columnas para diagnosticar
                            cols_preview = list(df.columns[:5])
                            print(f"      ‚ö†Ô∏è {file}: Sin columna de fecha. Columnas: {cols_preview}")
                    else:
                        print(f"      ‚ö†Ô∏è {file}: Archivo vac√≠o")
                        
                except Exception as e:
                    print(f"      ‚ùå {file}: {str(e)[:50]}...")
            else:
                print(f"      ‚ùå {file}: No encontrado")
    
    def _load_yfinance_data(self) -> None:
        """Cargar datos de yfinance"""
        print("   üìä Cargando datos yfinance...")
        
        tickers = {
            # ETFs principales
            'SPY': 'S&P 500',
            'QQQ': 'Nasdaq',
            'IWM': 'Russell 2000',
            'GLD': 'Gold',
            'SLV': 'Silver',
            'USO': 'Oil',
            'XLE': 'Energy',
            'TLT': 'Bonds',
            
            # Acciones blue chip
            'AAPL': 'Apple',
            'MSFT': 'Microsoft',
            'GOOGL': 'Google',
            'AMZN': 'Amazon',
            'TSLA': 'Tesla',
            'NVDA': 'Nvidia',
            'META': 'Meta',
            'JPM': 'JPMorgan'
        }
        
        for ticker, name in tickers.items():
            try:
                data = yf.download(
                    ticker, 
                    start='2020-01-01', 
                    end=datetime.now().strftime('%Y-%m-%d'),
                    progress=False
                )
                
                if not data.empty and len(data) > 100:
                    # Arreglar columnas MultiIndex PRIMERO
                    if isinstance(data.columns, pd.MultiIndex):
                        data.columns = data.columns.droplevel(1)
                    
                    # Luego limpiar nombres de columnas
                    data.columns = [str(col).lower().replace(' ', '_') for col in data.columns]
                    
                    self.data_sources[f'yf_{ticker.lower()}'] = data
                    print(f"      ‚úÖ {ticker} ({name}): {len(data):,} registros")
                else:
                    print(f"      ‚ö†Ô∏è {ticker}: Datos insuficientes")
                    
                time.sleep(0.1)  # Rate limiting
                
            except Exception as e:
                print(f"      ‚ùå {ticker}: {str(e)[:50]}...")
    
    def _load_tiingo_data(self) -> None:
        """Cargar datos de archivos CSV de Tiingo (previamente descargados)"""
        print("   üåê Cargando datos Tiingo desde CSV...")
        
        tiingo_csv_dir = os.path.join('Datos', 'Tiingo_CSV')
        
        if not os.path.exists(tiingo_csv_dir):
            print("      ‚ö†Ô∏è Directorio Tiingo_CSV no encontrado")
            print("      üí° Ejecuta 'python download_tiingo_data.py' para descargar datos")
            return
        
        # Obtener todos los archivos CSV de Tiingo
        csv_files = [f for f in os.listdir(tiingo_csv_dir) if f.endswith('.csv')]
        print(f"      üìä Encontrados {len(csv_files)} archivos CSV de Tiingo")
        
        for file in csv_files:
            try:
                file_path = os.path.join(tiingo_csv_dir, file)
                
                # Cargar CSV
                df = pd.read_csv(file_path, index_col=0, parse_dates=True)
                
                if len(df) > 0:
                    # Limpiar nombres de columnas
                    df.columns = [str(col).strip().lower().replace(' ', '_') for col in df.columns]
                    
                    # Crear clave descriptiva
                    base_name = file.replace('.csv', '').replace('_daily', '').replace('_1hour', '')
                    frequency = '_1hour' if '_1hour' in file else '_daily'
                    key = f'tiingo_{base_name.lower()}{frequency}'
                    
                    self.data_sources[key] = df
                    print(f"      ‚úÖ {file}: {len(df):,} registros ({df.index[0].strftime('%Y-%m-%d')} a {df.index[-1].strftime('%Y-%m-%d')})")
                else:
                    print(f"      ‚ö†Ô∏è {file}: Archivo vac√≠o")
                    
            except Exception as e:
                print(f"      ‚ùå {file}: Error - {str(e)[:50]}...")
        
        print(f"      üìà Total archivos Tiingo cargados: {len([k for k in self.data_sources.keys() if k.startswith('tiingo_')])}")
    
    def _load_ml_datasets(self) -> None:
        """Cargar datasets internos de ML de manera comprehensiva"""
        print("   üìÅ Cargando datasets ML...")
        
        dataset_path = os.path.join('Machine Learning', 'datasets', 'data')
        if os.path.exists(dataset_path):
            # Obtener TODOS los archivos CSV
            csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]
            print(f"      üìä Encontrados {len(csv_files)} archivos CSV")
            
            for file in csv_files:
                try:
                    file_path = os.path.join(dataset_path, file)
                    
                    # Intentar diferentes encodings
                    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
                    df = None
                    
                    for encoding in encodings:
                        try:
                            df = pd.read_csv(file_path, encoding=encoding)
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if df is None:
                        print(f"      ‚ùå {file}: Error de encoding")
                        continue
                    
                    if len(df) > 0:
                        # Limpiar columnas PRIMERO
                        df.columns = [str(col).strip().lower().replace(' ', '_') for col in df.columns]
                        
                        # Buscar y procesar fecha de manera m√°s robusta
                        date_processed = False
                        date_cols = ['date_time', 'date', 'timestamp', 'datetime', 'time']
                        
                        for col in date_cols:
                            if col in df.columns:
                                try:
                                    df[col] = pd.to_datetime(df[col], errors='coerce')
                                    valid_dates = df[col].notna().sum()
                                    
                                    # Solo usar como √≠ndice si >50% de las fechas son v√°lidas
                                    if valid_dates / len(df) > 0.5:
                                        df = df.dropna(subset=[col])
                                        df.set_index(col, inplace=True)
                                        df = df.sort_index()
                                        date_processed = True
                                        break
                                except:
                                    continue
                        
                        # Si no hay fecha v√°lida, usar √≠ndice num√©rico
                        if not date_processed:
                            # Mantener como DataFrame normal sin √≠ndice de fecha
                            pass
                        
                        # Guardar dataset
                        key = f"ml_{file.replace('.csv', '').replace(' ', '_').replace('-', '_')}"
                        self.data_sources[key] = df
                        
                        # Informaci√≥n detallada del dataset
                        cols_info = f"{list(df.columns)[:3]}..." if len(df.columns) > 3 else list(df.columns)
                        print(f"      ‚úÖ {file}: {len(df):,} registros, {len(df.columns)} columnas {cols_info}")
                    else:
                        print(f"      ‚ö†Ô∏è {file}: Vac√≠o")
                        
                except Exception as e:
                    print(f"      ‚ùå {file}: {str(e)[:50]}...")
            
            # Generar datasets sint√©ticos adicionales si hay pocos datos
            if len(csv_files) < 5:
                self._generate_synthetic_datasets()
        else:
            print("      ‚ö†Ô∏è Directorio datasets no encontrado")
            self._generate_synthetic_datasets()
    
    def _generate_synthetic_datasets(self) -> None:
        """Generar datasets sint√©ticos para testing comprehensivo"""
        print("      üîß Generando datasets sint√©ticos adicionales...")
        
        try:
            # 1. Dataset de tick data sint√©tico
            n_ticks = 5000
            start_date = pd.Timestamp('2023-01-01 09:30:00')
            dates = pd.date_range(start=start_date, periods=n_ticks, freq='1s')
            
            # Simulaci√≥n de precios con walk aleatorio
            np.random.seed(42)
            prices = 100 + np.cumsum(np.random.randn(n_ticks) * 0.01)
            volumes = np.random.randint(100, 10000, n_ticks)
            
            synthetic_tick = pd.DataFrame({
                'date_time': dates,
                'price': prices,
                'volume': volumes
            })
            
            self.data_sources['synthetic_tick_data'] = synthetic_tick
            print(f"      ‚úÖ synthetic_tick_data: {len(synthetic_tick):,} registros generados")
            
            # 2. Dataset de precios OHLCV sint√©tico
            n_days = 1000
            daily_dates = pd.date_range(start='2020-01-01', periods=n_days, freq='D')
            
            # Precios OHLCV
            base_price = 100
            daily_returns = np.random.randn(n_days) * 0.02
            close_prices = base_price * np.exp(np.cumsum(daily_returns))
            
            # OHLC basado en close
            high_prices = close_prices * (1 + np.abs(np.random.randn(n_days) * 0.01))
            low_prices = close_prices * (1 - np.abs(np.random.randn(n_days) * 0.01))
            open_prices = np.roll(close_prices, 1)
            open_prices[0] = close_prices[0]
            
            volumes = np.random.randint(10000, 1000000, n_days)
            
            synthetic_ohlcv = pd.DataFrame({
                'date': daily_dates,
                'open': open_prices,
                'high': high_prices,
                'low': low_prices,
                'close': close_prices,
                'volume': volumes
            }).set_index('date')
            
            self.data_sources['synthetic_ohlcv_data'] = synthetic_ohlcv
            print(f"      ‚úÖ synthetic_ohlcv_data: {len(synthetic_ohlcv):,} registros generados")
            
            # 3. Dataset multi-asset sint√©tico
            assets = ['ASSET_A', 'ASSET_B', 'ASSET_C']
            multi_asset_data = []
            
            for asset in assets:
                asset_prices = 100 + np.cumsum(np.random.randn(500) * 0.015)
                asset_volumes = np.random.randint(1000, 50000, 500)
                asset_dates = pd.date_range(start='2022-01-01', periods=500, freq='D')
                
                for i in range(len(asset_dates)):
                    multi_asset_data.append({
                        'date': asset_dates[i],
                        'asset': asset,
                        'price': asset_prices[i],
                        'volume': asset_volumes[i],
                        'returns': np.random.randn() * 0.02
                    })
            
            synthetic_multi = pd.DataFrame(multi_asset_data)
            self.data_sources['synthetic_multi_asset'] = synthetic_multi
            print(f"      ‚úÖ synthetic_multi_asset: {len(synthetic_multi):,} registros generados")
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è Error generando datos sint√©ticos: {str(e)[:50]}...")
    
    def _find_column(self, df: pd.DataFrame, keywords: List[str]) -> Optional[str]:
        """Encontrar columna que contenga alguna de las palabras clave"""
        for col in df.columns:
            col_str = str(col).strip().lower()
            if any(keyword in col_str for keyword in keywords):
                return col
        return None
    
    def _find_date_column_enhanced(self, df: pd.DataFrame) -> Optional[str]:
        """Detecci√≥n mejorada de columnas de fecha"""
        # Palabras clave m√°s completas
        date_keywords = [
            'date', 'fecha', 'time', 'datetime', 'timestamp', 
            'Date', 'Time', 'DateTime', 'Timestamp',
            'fecha_hora', 'fechahora', 'fecha_y_hora'
        ]
        
        # 1. Buscar por nombre de columna
        for col in df.columns:
            col_str = str(col).strip().lower()
            if any(keyword.lower() in col_str for keyword in date_keywords):
                return col
        
        # 2. Buscar por posici√≥n (primera columna si parece fecha)
        if len(df.columns) > 0:
            first_col = df.columns[0]
            try:
                # Intentar convertir una muestra a fecha
                sample = df[first_col].dropna().head(10)
                if len(sample) > 0:
                    pd.to_datetime(sample, errors='raise')
                    return first_col
            except:
                pass
        
        # 3. Buscar por tipo de datos
        for col in df.columns:
            try:
                sample = df[col].dropna().head(20)
                if len(sample) > 5:
                    # Intentar conversi√≥n de muestra
                    converted = pd.to_datetime(sample, errors='coerce')
                    # Si m√°s del 80% se convierte exitosamente
                    if converted.notna().sum() / len(sample) > 0.8:
                        return col
            except:
                continue
        
        return None
    
    def run_complete_validation(self) -> None:
        """Ejecutar validaci√≥n completa y profesional"""
        print("\nüöÄ INICIANDO VALIDACI√ìN COMPLETA PROFESIONAL")
        print("=" * 80)
        
        try:
            # 1. Cargar m√≥dulos
            self.load_all_modules()
            
            # 2. Cargar datos
            self.load_comprehensive_data()
            
            # 3. Validar cada categor√≠a
            self.validate_data_structures()
            self.validate_util_modules()
            self.validate_labeling_modules()
            self.validate_multiproduct_modules()
            
            # 4. Generar reportes y visualizaciones
            self._generate_comprehensive_report()
            self._create_professional_visualizations()
            
            # 5. Resumen final
            self._print_final_summary()
            
        except Exception as e:
            print(f"\n‚ùå ERROR CR√çTICO EN VALIDACI√ìN:")
            print(f"   {str(e)}")
            traceback.print_exc()
            
            # Guardar estado para debugging
            self._save_error_state(e)
    
    def validate_data_structures(self) -> None:
        """Validar todos los m√≥dulos de data_structures"""
        print("\nüìä VALIDANDO DATA STRUCTURES")
        print("-" * 50)
        
        if not self.modules.get('data_structures'):
            print("   ‚ùå No hay m√≥dulos de data_structures cargados")
            return
        
        for module_name, module in self.modules['data_structures'].items():
            print(f"\nüîç Validando {module_name}...")
            
            try:
                if module_name == 'standard_data_structures':
                    self._validate_standard_data_structures(module)
                elif module_name == 'imbalance_data_structures':
                    self._validate_imbalance_data_structures(module)
                elif module_name == 'run_data_structures':
                    self._validate_run_data_structures(module)
                elif module_name == 'time_data_structures':
                    self._validate_time_data_structures(module)
                elif module_name == 'base_bars':
                    self._validate_base_bars(module)
                
                print(f"   ‚úÖ {module_name} - Validaci√≥n completada")
                
            except Exception as e:
                print(f"   ‚ùå {module_name} - Error: {str(e)}")
                self.errors.append(f"Error en {module_name}: {e}")
    
    def _validate_standard_data_structures(self, module) -> None:
        """Validar standard_data_structures con datos reales y formato correcto"""
        # Obtener datos apropiados para el test
        sample_data = self._get_sample_tick_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        # Listar funciones disponibles
        functions = [f for f in dir(module) if not f.startswith('_') and callable(getattr(module, f))]
        print(f"      üìã Funciones encontradas: {len(functions)}")
        
        # Debug: mostrar estructura de datos
        print(f"      üìä Estructura de datos: {sample_data.shape}")
        print(f"      üìä Columnas: {list(sample_data.columns)}")
        print(f"      üìä Tipos: {sample_data.dtypes.to_dict()}")
        
        results = {}
        
        # Test get_tick_bars con datos en formato correcto
        if hasattr(module, 'get_tick_bars'):
            try:
                test_data = sample_data.head(1000).copy()
                print(f"      üß™ Testing get_tick_bars con {len(test_data)} registros...")
                
                # Pasar como DataFrame con el formato correcto
                bars = module.get_tick_bars(test_data, threshold=100)
                
                if isinstance(bars, pd.DataFrame) and not bars.empty:
                    results['get_tick_bars'] = {
                        'status': 'passed',
                        'output_rows': len(bars),
                        'output_cols': len(bars.columns),
                        'columns': list(bars.columns),
                        'memory_mb': bars.memory_usage(deep=True).sum() / 1024 / 1024
                    }
                    print(f"      ‚úÖ get_tick_bars: {len(bars)} barras generadas")
                    self.stats['passed_tests'] += 1
                else:
                    results['get_tick_bars'] = {'status': 'failed', 'reason': 'Empty or invalid output'}
                    print(f"      ‚ùå get_tick_bars: Salida inv√°lida")
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                results['get_tick_bars'] = {'status': 'failed', 'reason': str(e)}
                print(f"      ‚ùå get_tick_bars: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
        
        # Test get_volume_bars
        if hasattr(module, 'get_volume_bars'):
            try:
                test_data = sample_data.head(1000).copy()
                print(f"      üß™ Testing get_volume_bars...")
                
                bars = module.get_volume_bars(test_data, threshold=1000)
                
                if isinstance(bars, pd.DataFrame) and not bars.empty:
                    results['get_volume_bars'] = {
                        'status': 'passed',
                        'output_rows': len(bars),
                        'output_cols': len(bars.columns),
                        'columns': list(bars.columns)
                    }
                    print(f"      ‚úÖ get_volume_bars: {len(bars)} barras generadas")
                    self.stats['passed_tests'] += 1
                else:
                    results['get_volume_bars'] = {'status': 'failed', 'reason': 'Empty output'}
                    print(f"      ‚ùå get_volume_bars: Salida vac√≠a")
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                results['get_volume_bars'] = {'status': 'failed', 'reason': str(e)}
                print(f"      ‚ùå get_volume_bars: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
        
        # Test get_dollar_bars
        if hasattr(module, 'get_dollar_bars'):
            try:
                test_data = sample_data.head(1000).copy()
                print(f"      üß™ Testing get_dollar_bars...")
                
                bars = module.get_dollar_bars(test_data, threshold=10000)
                
                if isinstance(bars, pd.DataFrame) and not bars.empty:
                    results['get_dollar_bars'] = {
                        'status': 'passed',
                        'output_rows': len(bars),
                        'output_cols': len(bars.columns),
                        'columns': list(bars.columns)
                    }
                    print(f"      ‚úÖ get_dollar_bars: {len(bars)} barras generadas")
                    self.stats['passed_tests'] += 1
                else:
                    results['get_dollar_bars'] = {'status': 'failed', 'reason': 'Empty output'}
                    print(f"      ‚ùå get_dollar_bars: Salida vac√≠a")
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                results['get_dollar_bars'] = {'status': 'failed', 'reason': str(e)}
                print(f"      ‚ùå get_dollar_bars: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
        
        self.results['data_structures']['standard_data_structures'] = {
            'total_functions': len(functions),
            'tested_functions': len(results),
            'results': results
        }
        
        self.stats['total_functions'] += len(functions)
    
    def _validate_imbalance_data_structures(self, module) -> None:
        """Validar imbalance_data_structures"""
        functions = [f for f in dir(module) if not f.startswith('_') and callable(getattr(module, f))]
        print(f"      üìã Funciones encontradas: {len(functions)}")
        
        # Implementar tests espec√≠ficos para imbalance bars
        # TODO: Completar cuando se tenga m√°s informaci√≥n sobre las funciones
        
    def _validate_run_data_structures(self, module) -> None:
        """Validar run_data_structures"""
        functions = [f for f in dir(module) if not f.startswith('_') and callable(getattr(module, f))]
        print(f"      üìã Funciones encontradas: {len(functions)}")
        
        # Implementar tests espec√≠ficos para run bars
        # TODO: Completar cuando se tenga m√°s informaci√≥n sobre las funciones
        
    def _validate_time_data_structures(self, module) -> None:
        """Validar time_data_structures"""
        functions = [f for f in dir(module) if not f.startswith('_') and callable(getattr(module, f))]
        print(f"      üìã Funciones encontradas: {len(functions)}")
        
        # Implementar tests espec√≠ficos para time bars
        # TODO: Completar cuando se tenga m√°s informaci√≥n sobre las funciones
        
    def _validate_base_bars(self, module) -> None:
        """Validar base_bars"""
        functions = [f for f in dir(module) if not f.startswith('_') and callable(getattr(module, f))]
        print(f"      üìã Funciones encontradas: {len(functions)}")
        
        # Implementar tests espec√≠ficos para base bars
        # TODO: Completar cuando se tenga m√°s informaci√≥n sobre las funciones
    
    def validate_util_modules(self) -> None:
        """Validar todos los m√≥dulos de util"""
        print("\n‚öôÔ∏è VALIDANDO UTIL MODULES")
        print("-" * 50)
        
        util_modules = self.modules.get('util', {})
        
        for module_name, module in util_modules.items():
            try:
                print(f"\nüîç Validando {module_name}...")
                functions = [attr for attr in dir(module) if not attr.startswith('_') and callable(getattr(module, attr))]
                print(f"      üìã Funciones encontradas: {len(functions)}")
                
                # Validaciones espec√≠ficas por m√≥dulo
                if module_name == 'volume_classifier':
                    self._validate_volume_classifier(module)
                elif module_name == 'fast_ewma':
                    self._validate_fast_ewma(module)
                elif module_name == 'volatility':
                    self._validate_volatility(module)
                elif module_name == 'misc':
                    self._validate_misc(module)
                elif module_name == 'generate_dataset':
                    self._validate_generate_dataset(module)
                elif module_name == 'multiprocess':
                    self._validate_multiprocess(module)
                
                print(f"   ‚úÖ {module_name} - Validaci√≥n completada")
                self.stats['passed_tests'] += 1
                
            except Exception as e:
                error_msg = f"Error validando {module_name}: {str(e)}"
                self.errors.append(error_msg)
                print(f"   ‚ùå {module_name} - Error: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
    
    def validate_labeling_modules(self) -> None:
        """Validar todos los m√≥dulos de labeling"""
        print("\nüè∑Ô∏è VALIDANDO LABELING MODULES")
        print("-" * 50)
        
        labeling_modules = self.modules.get('labeling', {})
        
        for module_name, module in labeling_modules.items():
            try:
                print(f"\nüîç Validando {module_name}...")
                functions = [attr for attr in dir(module) if not attr.startswith('_') and callable(getattr(module, attr))]
                print(f"      üìã Funciones encontradas: {len(functions)}")
                
                # Validaciones espec√≠ficas por m√≥dulo
                if module_name == 'labeling':
                    self._validate_main_labeling(module)
                elif module_name == 'trend_scanning':
                    self._validate_trend_scanning(module)
                elif module_name == 'bull_bear':
                    self._validate_bull_bear(module)
                elif module_name == 'excess_over_mean':
                    self._validate_excess_over_mean(module)
                elif module_name == 'excess_over_median':
                    self._validate_excess_over_median(module)
                elif module_name == 'fixed_time_horizon':
                    self._validate_fixed_time_horizon(module)
                elif module_name == 'raw_return':
                    self._validate_raw_return(module)
                elif module_name == 'tail_sets':
                    self._validate_tail_sets(module)
                elif module_name == 'return_vs_benchmark':
                    self._validate_return_vs_benchmark(module)
                elif module_name == 'matrix_flags':
                    self._validate_matrix_flags(module)
                
                print(f"   ‚úÖ {module_name} - Validaci√≥n completada")
                self.stats['passed_tests'] += 1
                
            except Exception as e:
                error_msg = f"Error validando {module_name}: {str(e)}"
                self.errors.append(error_msg)
                print(f"   ‚ùå {module_name} - Error: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
    
    def validate_multiproduct_modules(self) -> None:
        """Validar todos los m√≥dulos de multi_product"""
        print("\nüîÑ VALIDANDO MULTI-PRODUCT MODULES")
        print("-" * 50)
        
        multiproduct_modules = self.modules.get('multi_product', {})
        
        for module_name, module in multiproduct_modules.items():
            try:
                print(f"\nüîç Validando {module_name}...")
                functions = [attr for attr in dir(module) if not attr.startswith('_') and callable(getattr(module, attr))]
                print(f"      üìã Funciones encontradas: {len(functions)}")
                
                # Validaciones espec√≠ficas por m√≥dulo
                if module_name == 'etf_trick':
                    self._validate_etf_trick(module)
                elif module_name == 'futures_roll':
                    self._validate_futures_roll(module)
                
                print(f"   ‚úÖ {module_name} - Validaci√≥n completada")
                self.stats['passed_tests'] += 1
                
            except Exception as e:
                error_msg = f"Error validando {module_name}: {str(e)}"
                self.errors.append(error_msg)
                print(f"   ‚ùå {module_name} - Error: {str(e)[:100]}...")
                self.stats['failed_tests'] += 1
    
    # ========================================================================
    # FUNCIONES DE VALIDACI√ìN ESPEC√çFICAS POR M√ìDULO
    # ========================================================================
    
    # UTIL MODULES VALIDATIONS
    
    def _validate_volume_classifier(self, module):
        """Validar m√≥dulo volume_classifier"""
        # Obtener datos de muestra
        sample_data = self._get_sample_tick_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        # Buscar funci√≥n principal (generalmente bulk_class_xxx)
        functions = [name for name in dir(module) if 'bulk_class' in name.lower() or 'classify' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            
            # Test b√°sico con datos peque√±os
            test_prices = sample_data['price'].head(100)
            result = func(test_prices)
            print(f"      ‚úÖ Clasificaciones generadas: {len(result) if hasattr(result, '__len__') else 'Scalar'}")
    
    def _validate_fast_ewma(self, module):
        """Validar m√≥dulo fast_ewma con tipos correctos"""
        print("      üîç Generando datos para fast_ewma...")
        
        # fast_ewma requiere exactamente: np.array de float64 + par√°metro int
        # Generar datos de testing simples
        test_data = np.random.randn(100).cumsum() + 100.0  # Random walk de precios
        test_data = test_data.astype(np.float64)  # CR√çTICO: debe ser float64
        
        print(f"      üìä Datos generados: shape={test_data.shape}, dtype={test_data.dtype}")
        
        # Test de todas las funciones EWMA disponibles
        ewma_functions = [name for name in dir(module) if 'ewma' in name.lower() and not name.startswith('_')]
        print(f"      üìã Funciones EWMA encontradas: {ewma_functions}")
        
        results = {}
        
        for func_name in ewma_functions:
            try:
                func = getattr(module, func_name)
                print(f"      üß™ Testing {func_name}...")
                
                if func_name == 'ewma':
                    # ewma(arr_in, window) - window debe ser int
                    result = func(test_data, 10)
                    
                elif func_name == 'ewma_alpha':
                    # ewma_alpha(arr_in, alpha) - alpha debe ser float entre 0 y 1
                    result = func(test_data, 0.3)
                    
                elif func_name == 'ewma_halflife':
                    # ewma_halflife(arr_in, halflife) - halflife debe ser int
                    result = func(test_data, 5)
                    
                elif func_name == 'ewma_com':
                    # ewma_com(arr_in, com) - com debe ser float positivo
                    result = func(test_data, 9.0)
                    
                elif func_name == 'ewma_vectorized':
                    # ewma_vectorized(arr_in, window) - similar a ewma b√°sico
                    result = func(test_data, 10)
                    
                elif func_name == 'get_ewma_info':
                    # get_ewma_info() no acepta par√°metros - es funci√≥n informativa
                    result = func()
                    # Esta funci√≥n retorna informaci√≥n, no array
                    if result is not None:
                        print(f"      ‚úÖ {func_name}: Informaci√≥n obtenida")
                        results[func_name] = 'SUCCESS'
                        self.stats['passed_tests'] += 1
                    else:
                        print(f"      ‚ö†Ô∏è {func_name}: Sin informaci√≥n")
                        results[func_name] = 'NULL_RESULT'
                        self.stats['failed_tests'] += 1
                    continue  # Skip validaci√≥n normal
                    
                else:
                    # Funci√≥n desconocida, intentar con window
                    result = func(test_data, 10)
                
                # Validar resultado
                if result is not None:
                    if hasattr(result, '__len__'):
                        print(f"      ‚úÖ {func_name}: {len(result)} resultados generados")
                    else:
                        print(f"      ‚úÖ {func_name}: Objeto generado")
                    results[func_name] = 'SUCCESS'
                    self.stats['passed_tests'] += 1
                else:
                    print(f"      ‚ö†Ô∏è {func_name}: Resultado None")
                    results[func_name] = 'NULL_RESULT'
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                error_msg = str(e)[:80]
                print(f"      ‚ùå {func_name}: {error_msg}")
                results[func_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Guardar resultados
        self.results['util']['fast_ewma'] = {
            'tested_functions': len(ewma_functions),
            'results': results,
            'data_shape': test_data.shape,
            'data_dtype': str(test_data.dtype)
        }
    
    def _validate_volatility(self, module):
        """Validar m√≥dulo volatility"""
        sample_data = self._get_sample_tick_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'volatility' in name.lower() or 'vol' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            
            test_prices = sample_data['price'].head(100)
            try:
                result = func(test_prices)
                print(f"      ‚úÖ Volatilidad calculada: {len(result) if hasattr(result, '__len__') else 'Scalar'} valores")
            except Exception as e:
                print(f"      ‚ö†Ô∏è Funci√≥n requiere par√°metros espec√≠ficos: {str(e)[:50]}...")
    
    def _validate_misc(self, module):
        """Validar m√≥dulo misc (miscel√°neos)"""
        functions = [name for name in dir(module) if not name.startswith('_') and callable(getattr(module, name))]
        print(f"      üß™ Testing {len(functions)} funciones miscel√°neas...")
        
        for func_name in functions[:3]:  # Test solo las primeras 3
            try:
                func = getattr(module, func_name)
                print(f"      ‚úÖ {func_name}: disponible")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {func_name}: {str(e)[:30]}...")
    
    def _validate_generate_dataset(self, module):
        """Validar m√≥dulo generate_dataset"""
        functions = [name for name in dir(module) if 'generate' in name.lower() or 'create' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                # Intentar generar dataset peque√±o
                result = func(100)  # Asumir que acepta tama√±o
                print(f"      ‚úÖ Dataset generado: {len(result) if hasattr(result, '__len__') else 'Generado'}")
            except:
                print(f"      ‚úÖ Funci√≥n {functions[0]} disponible (requiere par√°metros espec√≠ficos)")
    
    def _validate_multiprocess(self, module):
        """Validar m√≥dulo multiprocess"""
        functions = [name for name in dir(module) if 'process' in name.lower() or 'parallel' in name.lower()]
        print(f"      üß™ Testing m√≥dulo multiprocess...")
        print(f"      ‚úÖ Funciones multiprocess disponibles: {len(functions)}")
    
    # LABELING MODULES VALIDATIONS
    
    def _validate_main_labeling(self, module):
        """Validar m√≥dulo principal de labeling con argumentos correctos"""
        print("      üîç Preparando datos para labeling principal...")
        
        # Generar datos de precios con √≠ndice de fecha para labeling
        n_periods = 200
        dates = pd.date_range('2023-01-01', periods=n_periods, freq='D')
        
        # Simular serie de precios para close
        np.random.seed(44)
        returns = np.random.randn(n_periods) * 0.02
        prices = pd.Series(100 * np.exp(np.cumsum(returns)), index=dates, name='close')
        
        print(f"      üìä Precios generados: {len(prices)} puntos, rango: {prices.index[0]} a {prices.index[-1]}")
        
        # Buscar todas las funciones de labeling (filtrar typing imports)
        functions = [name for name in dir(module) 
                    if not name.startswith('_') 
                    and callable(getattr(module, name))
                    and name not in ['List', 'Optional', 'Union', 'Dict', 'Any', 'ProcessPoolExecutor', 'as_completed', 'datetime', 'timedelta']]
        print(f"      üìã Funciones encontradas: {functions}")
        
        results = {}
        
        for func_name in functions:
            try:
                func = getattr(module, func_name)
                print(f"      üß™ Testing {func_name}...")
                
                if func_name == 'add_vertical_barrier':
                    # add_vertical_barrier(t_events, close, num_days=1)
                    # t_events: Series de eventos (fechas), close: Series de precios
                    t_events = prices.index[::20]  # Cada 20 d√≠as como evento
                    result = func(t_events, prices, num_days=5)
                    
                elif func_name == 'get_events':
                    # get_events necesita close, t_events, pt_sl, target, min_ret
                    t_events = prices.index[::15]  # Eventos
                    pt_sl = pd.Series([0.02] * len(t_events), index=t_events)  # profit taking / stop loss
                    trgt = pd.Series([0.01] * len(t_events), index=t_events)   # target
                    min_ret = 0.005  # Retorno m√≠nimo requerido
                    result = func(close=prices, t_events=t_events, pt_sl=pt_sl, target=trgt, min_ret=min_ret)
                    
                elif func_name == 'apply_pt_sl_on_t1':
                    # apply_pt_sl_on_t1(molecule, close, events, pt_sl)
                    close_subset = prices.head(50)
                    events_index = close_subset.index[::5]
                    # Crear DataFrame de eventos con t1, trgt Y side
                    events_df = pd.DataFrame({
                        't1': events_index[1:len(events_index)] if len(events_index) > 1 else [events_index[-1]],
                        'trgt': [0.01] * (len(events_index)-1 if len(events_index) > 1 else 1),
                        'side': [1] * (len(events_index)-1 if len(events_index) > 1 else 1)  # COLUMNA SIDE REQUERIDA
                    }, index=events_index[:-1] if len(events_index) > 1 else events_index)
                    
                    pt_sl = np.array([0.02, 0.02])  # [profit_taking, stop_loss]
                    molecule = list(events_df.index[:3])  # Lista de datetime como molecule
                    result = func(molecule=molecule, close=close_subset, events=events_df, pt_sl=pt_sl)
                    
                elif func_name == 'get_bins':
                    # get_bins(triple_barrier_events, close) - triple_barrier_events debe ser DataFrame
                    events_index = prices.index[::10]
                    # Crear DataFrame de eventos triple barrier correctamente estructurado
                    triple_barrier_events = pd.DataFrame({
                        't1': events_index[1:len(events_index)] if len(events_index) > 1 else [events_index[-1]],
                        'trgt': [0.01] * (len(events_index)-1 if len(events_index) > 1 else 1),
                        'side': [1] * (len(events_index)-1 if len(events_index) > 1 else 1)
                    }, index=events_index[:-1] if len(events_index) > 1 else events_index)
                    result = func(triple_barrier_events=triple_barrier_events, close=prices)
                    
                elif func_name == 'drop_labels':
                    # drop_labels(events, min_pct=0.05) - events debe ser DataFrame con columna 'bin'
                    events_index = prices.index[::8][:20]  # Tomar exactamente 20 elementos
                    bins_data = [1, -1, 0, 1, -1] * 4  # Exactamente 20 elementos
                    dummy_events = pd.DataFrame({
                        'bin': bins_data
                    }, index=events_index)
                    result = func(events=dummy_events, min_pct=0.1)
                    
                elif 'cusum' in func_name.lower() or 'filter' in func_name.lower():
                    # CUSUM filter
                    returns = prices.pct_change().dropna()
                    result = func(returns, threshold=0.02)
                    
                elif 'daily_vol' in func_name.lower() or 'volatility' in func_name.lower():
                    # get_daily_vol(close, span0=100)
                    result = func(close=prices, span0=20)
                    
                elif func_name == 'mp_pandas_obj':
                    # mp_pandas_obj(func, pd_obj, num_threads=1, **kwargs)
                    # Esta funci√≥n requiere una funci√≥n para paralelizar y un objeto pandas
                    # Crear una funci√≥n dummy simple para testing
                    def dummy_func(data_slice):
                        return data_slice.head(5)  # Funci√≥n simple que retorna primeros 5 elementos
                    
                    # pd_obj debe ser una tupla (nombre_arg, objeto_pandas)
                    pd_obj = ('data', prices.head(20))
                    result = func(func=dummy_func, pd_obj=pd_obj, num_threads=1)
                
                elif func_name == 'barrier_touched':
                    # barrier_touched(out_df, events) - requiere DataFrames con columnas espec√≠ficas
                    # out_df: DataFrame con 'ret' y 'trgt', events: DataFrame con 'pt' y 'sl'
                    
                    events_index = prices.index[::10][:10]  # Tomar solo 10 eventos
                    
                    # Crear out_df con returns y targets (resultado t√≠pico de get_bins)
                    out_df = pd.DataFrame({
                        'ret': np.random.randn(len(events_index)) * 0.02,  # Returns observados
                        'trgt': np.full(len(events_index), 0.01),  # Targets
                        'bin': np.random.choice([-1, 0, 1], len(events_index))  # Labels existentes
                    }, index=events_index)
                    
                    # Crear events DataFrame con profit taking (pt) y stop loss (sl) multipliers
                    events_df = pd.DataFrame({
                        'pt': np.full(len(events_index), 2.0),  # Profit taking multiplier (ej: 2x target)
                        'sl': np.full(len(events_index), 2.0),  # Stop loss multiplier (ej: 2x target)
                        't1': events_index + pd.Timedelta(days=5),  # Tiempo de salida
                        'trgt': np.full(len(events_index), 0.01),  # Targets
                        'side': np.ones(len(events_index))  # Lado de la posici√≥n
                    }, index=events_index)
                    
                    result = func(out_df, events_df)
                
                else:
                    # Funci√≥n gen√©rica, intentar con prices
                    try:
                        result = func(prices)
                    except:
                        # Si falla, intentar con returns
                        returns = prices.pct_change().dropna()
                        result = func(returns)
                
                # Validar resultado
                if result is not None:
                    if hasattr(result, '__len__'):
                        print(f"      ‚úÖ {func_name}: {len(result)} resultados generados")
                    else:
                        print(f"      ‚úÖ {func_name}: Objeto generado")
                    results[func_name] = 'SUCCESS'
                    self.stats['passed_tests'] += 1
                else:
                    print(f"      ‚ö†Ô∏è {func_name}: Resultado None")
                    results[func_name] = 'NULL_RESULT'
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                error_msg = str(e)[:100]
                print(f"      ‚ùå {func_name}: {error_msg}")
                results[func_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Guardar resultados
        if 'labeling' not in self.results:
            self.results['labeling'] = {}
        self.results['labeling']['main_labeling'] = {
            'tested_functions': len(functions),
            'results': results,
            'input_length': len(prices)
        }
    
    def _validate_trend_scanning(self, module):
        """Validar m√≥dulo trend_scanning"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'trend' in name.lower() or 'scan' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Trend scanning completado: {len(result) if hasattr(result, '__len__') else 'Completado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
    
    def _validate_bull_bear(self, module):
        """Validar m√≥dulo bull_bear"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if any(x in name.lower() for x in ['bull', 'bear', 'regime'])]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Bull/Bear analysis: {len(result) if hasattr(result, '__len__') else 'Completado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
    
    def _validate_excess_over_mean(self, module):
        """Validar m√≥dulo excess_over_mean con DataFrame multi-asset correcto"""
        print("      üîç Generando DataFrame multi-asset para excess_over_mean...")
        
        # excess_over_mean necesita DataFrame con m√∫ltiples columnas de precios
        # Generar datos sint√©ticos de m√∫ltiples activos
        n_periods = 100
        dates = pd.date_range('2023-01-01', periods=n_periods, freq='D')
        
        # Simular precios de 4 activos con correlaciones diferentes
        np.random.seed(42)
        base_returns = np.random.randn(n_periods, 4) * 0.02
        base_returns[:, 1] += base_returns[:, 0] * 0.3  # Asset B correlacionado con A
        base_returns[:, 2] -= base_returns[:, 0] * 0.2  # Asset C anti-correlacionado con A
        
        prices = pd.DataFrame(
            100 * np.exp(np.cumsum(base_returns, axis=0)),
            index=dates,
            columns=['STOCK_A', 'STOCK_B', 'STOCK_C', 'STOCK_D']
        )
        
        print(f"      üìä DataFrame creado: {prices.shape}, columnas: {list(prices.columns)}")
        print(f"      üìä Rango de datos: {prices.index[0]} a {prices.index[-1]}")
        
        # Buscar funciones de excess over mean (filtrar typing imports)
        functions = [name for name in dir(module) 
                    if not name.startswith('_') 
                    and callable(getattr(module, name))
                    and name not in ['Union', 'Optional', 'List', 'Dict', 'Any']]
        print(f"      üìã Funciones encontradas: {functions}")
        
        results = {}
        
        for func_name in functions:
            try:
                func = getattr(module, func_name)
                print(f"      üß™ Testing {func_name}...")
                
                # La mayor√≠a de funciones de labeling requieren solo el DataFrame de precios
                result = func(prices)
                
                if result is not None:
                    if hasattr(result, '__len__'):
                        print(f"      ‚úÖ {func_name}: {len(result)} labels/valores generados")
                    else:
                        print(f"      ‚úÖ {func_name}: Resultado escalar/objeto generado")
                    results[func_name] = 'SUCCESS'
                    self.stats['passed_tests'] += 1
                else:
                    print(f"      ‚ö†Ô∏è {func_name}: Resultado None")
                    results[func_name] = 'NULL_RESULT'
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                error_msg = str(e)[:100]
                print(f"      ‚ùå {func_name}: {error_msg}")
                results[func_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Guardar resultados
        if 'labeling' not in self.results:
            self.results['labeling'] = {}
        self.results['labeling']['excess_over_mean'] = {
            'tested_functions': len(functions),
            'results': results,
            'input_shape': prices.shape,
            'input_columns': list(prices.columns)
        }
    
    def _validate_excess_over_median(self, module):
        """Validar m√≥dulo excess_over_median con DataFrame multi-asset correcto"""
        print("      üîç Generando DataFrame multi-asset para excess_over_median...")
        
        # Similar a excess_over_mean, necesita DataFrame multi-asset
        n_periods = 100
        dates = pd.date_range('2023-01-01', periods=n_periods, freq='D')
        
        # Simular precios con diferentes distribuciones
        np.random.seed(43)  # Seed diferente para variabilidad
        base_returns = np.random.randn(n_periods, 3) * 0.015
        
        # A√±adir sesgos para testing de median
        base_returns[:, 1] += np.random.exponential(0.005, n_periods) - 0.005  # Sesgo positivo
        base_returns[:, 2] -= np.random.exponential(0.005, n_periods) - 0.005  # Sesgo negativo
        
        prices = pd.DataFrame(
            100 * np.exp(np.cumsum(base_returns, axis=0)),
            index=dates,
            columns=['ASSET_X', 'ASSET_Y', 'ASSET_Z']
        )
        
        print(f"      üìä DataFrame creado: {prices.shape}, columnas: {list(prices.columns)}")
        
        # Buscar funciones de excess over median (filtrar typing imports)
        functions = [name for name in dir(module) 
                    if not name.startswith('_') 
                    and callable(getattr(module, name))
                    and name not in ['Union', 'Optional', 'List', 'Dict', 'Any']]
        print(f"      üìã Funciones encontradas: {functions}")
        
        results = {}
        
        for func_name in functions:
            try:
                func = getattr(module, func_name)
                print(f"      üß™ Testing {func_name}...")
                
                result = func(prices)
                
                if result is not None:
                    if hasattr(result, '__len__'):
                        print(f"      ‚úÖ {func_name}: {len(result)} labels/valores generados")
                    else:
                        print(f"      ‚úÖ {func_name}: Resultado escalar/objeto generado")
                    results[func_name] = 'SUCCESS'
                    self.stats['passed_tests'] += 1
                else:
                    print(f"      ‚ö†Ô∏è {func_name}: Resultado None")
                    results[func_name] = 'NULL_RESULT'
                    self.stats['failed_tests'] += 1
                    
            except Exception as e:
                error_msg = str(e)[:100]
                print(f"      ‚ùå {func_name}: {error_msg}")
                results[func_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Guardar resultados
        if 'labeling' not in self.results:
            self.results['labeling'] = {}
        self.results['labeling']['excess_over_median'] = {
            'tested_functions': len(functions),
            'results': results,
            'input_shape': prices.shape,
            'input_columns': list(prices.columns)
        }
    
    def _validate_fixed_time_horizon(self, module) -> None:
        """Validar m√≥dulo fixed_time_horizon"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if any(x in name.lower() for x in ['fixed', 'time', 'horizon'])]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Fixed time horizon: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
    
    def _validate_raw_return(self, module):
        """Validar m√≥dulo raw_return"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'return' in name.lower() or 'raw' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Raw returns: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
    
    def _validate_tail_sets(self, module):
        """Validar m√≥dulo tail_sets"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'tail' in name.lower() or 'set' in name.lower()]
        classes = [name for name in dir(module) if name[0].isupper() and hasattr(getattr(module, name), '__call__')]
        
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Tail sets: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
        
        # Test clases si existen
        for class_name in classes:
            try:
                cls = getattr(module, class_name)
                print(f"      üß™ Testing {class_name}...")
                if 'TailSet' in class_name:
                    print(f"      ‚ö†Ô∏è Clase {class_name} requiere par√°metros espec√≠ficos de inicializaci√≥n")
                    print(f"      ‚úÖ Clase {class_name} disponible para uso avanzado")
                else:
                    print(f"      ‚úÖ {class_name}: disponible")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {class_name}: {str(e)[:30]}...")

    def _validate_return_vs_benchmark(self, module):
        """Validar m√≥dulo return_vs_benchmark"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'return' in name.lower() or 'benchmark' in name.lower()]
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Return vs benchmark: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")

    def _validate_matrix_flags(self, module):
        """Validar m√≥dulo matrix_flags"""
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if 'matrix' in name.lower() or 'flag' in name.lower()]
        classes = [name for name in dir(module) if name[0].isupper() and hasattr(getattr(module, name), '__call__')]
        
        if functions:
            func = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                result = func(sample_data.head(50))
                print(f"      ‚úÖ Matrix flags: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:50]}...")
        
        # Test clases si existen
        for class_name in classes:
            try:
                cls = getattr(module, class_name)
                print(f"      üß™ Testing {class_name}...")
                if 'MatrixFlag' in class_name:
                    print(f"      ‚ö†Ô∏è Clase {class_name} requiere par√°metros espec√≠ficos de inicializaci√≥n")
                    print(f"      ‚úÖ Clase {class_name} disponible para uso avanzado")
                else:
                    print(f"      ‚úÖ {class_name}: disponible")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {class_name}: {str(e)[:30]}...")

    # MULTI-PRODUCT MODULES VALIDATIONS

    def _validate_etf_trick(self, module):
        """Validar m√≥dulo etf_trick con argumentos correctos"""
        print("      üîç Preparando datos para ETF trick...")
        
        # Generar datos sint√©ticos de m√∫ltiples activos para ETF trick
        n_periods = 50
        dates = pd.date_range('2023-01-01', periods=n_periods, freq='D')
        
        # Simular precios de activos subyacentes y ETF
        np.random.seed(45)
        
        # Precios de activos subyacentes
        underlying_returns = np.random.randn(n_periods, 3) * 0.015
        underlying_prices = pd.DataFrame(
            100 * np.exp(np.cumsum(underlying_returns, axis=0)),
            index=dates,
            columns=['ASSET_1', 'ASSET_2', 'ASSET_3']
        )
        
        # Precio del ETF (combinaci√≥n ponderada)
        etf_weights = np.array([0.4, 0.35, 0.25])
        etf_price = pd.Series(
            (underlying_prices * etf_weights).sum(axis=1),
            index=dates,
            name='ETF_PRICE'
        )
        
        print(f"      üìä Datos ETF generados: {n_periods} per√≠odos, {len(underlying_prices.columns)} activos")
        
        # Buscar funciones y clases de ETF trick
        functions = [name for name in dir(module) 
                    if not name.startswith('_') 
                    and callable(getattr(module, name))
                    and not name[0].isupper()]  # Excluir clases
        
        classes = [name for name in dir(module) 
                  if name[0].isupper() 
                  and hasattr(getattr(module, name), '__call__')]
        
        print(f"      üìã Funciones encontradas: {functions}")
        print(f"      üìã Clases encontradas: {classes}")
        
        results = {}
        
        # Test funciones
        for func_name in functions:
            try:
                func = getattr(module, func_name)
                print(f"      üß™ Testing function {func_name}...")
                
                if 'create_etf_trick_from_csv' in func_name:
                    # Esta funci√≥n requiere rutas de archivos CSV
                    print(f"      ‚ö†Ô∏è {func_name}: Requiere rutas de archivos CSV espec√≠ficos")
                    results[func_name] = 'REQUIRES_CSV_PATHS'
                    self.stats['failed_tests'] += 1
                    
                elif 'create_etf_trick_from_dataframes' in func_name:
                    # Esta funci√≥n requiere DataFrames espec√≠ficos
                    print(f"      ‚ö†Ô∏è {func_name}: Requiere m√∫ltiples DataFrames espec√≠ficos")
                    results[func_name] = 'REQUIRES_MULTIPLE_DATAFRAMES'
                    self.stats['failed_tests'] += 1
                    
                else:
                    # Funci√≥n gen√©rica
                    try:
                        result = func(underlying_prices)
                        if result is not None:
                            print(f"      ‚úÖ {func_name}: Resultado generado")
                            results[func_name] = 'SUCCESS'
                            self.stats['passed_tests'] += 1
                        else:
                            print(f"      ‚ö†Ô∏è {func_name}: Resultado None")
                            results[func_name] = 'NULL_RESULT'
                            self.stats['failed_tests'] += 1
                    except:
                        # Intentar con Serie
                        result = func(etf_price)
                        print(f"      ‚úÖ {func_name}: Resultado generado con Serie")
                        results[func_name] = 'SUCCESS'
                        self.stats['passed_tests'] += 1
                        
            except Exception as e:
                error_msg = str(e)[:100]
                print(f"      ‚ùå {func_name}: {error_msg}")
                results[func_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Test clases
        for class_name in classes:
            try:
                cls = getattr(module, class_name)
                print(f"      üß™ Testing class {class_name}...")
                
                if class_name == 'ETFTrick':
                    # Intentar crear instancia con datos b√°sicos
                    try:
                        # ETFTrick t√≠picamente requiere precios de activos subyacentes y del ETF
                        instance = cls(underlying_prices, etf_price)
                        print(f"      ‚úÖ {class_name}: Instancia creada exitosamente")
                        
                        # Test m√©todos b√°sicos si existen
                        if hasattr(instance, 'get_etf_series'):
                            etf_series = instance.get_etf_series()
                            print(f"      ‚úÖ {class_name}.get_etf_series(): {len(etf_series) if hasattr(etf_series, '__len__') else 'Calculado'}")
                            
                        results[class_name] = 'SUCCESS'
                        self.stats['passed_tests'] += 1
                        
                    except Exception as e:
                        print(f"      ‚ö†Ô∏è {class_name}: Requiere par√°metros espec√≠ficos - {str(e)[:50]}...")
                        results[class_name] = 'REQUIRES_SPECIFIC_PARAMS'
                        self.stats['failed_tests'] += 1
                else:
                    print(f"      ‚úÖ {class_name}: disponible")
                    results[class_name] = 'AVAILABLE'
                    self.stats['passed_tests'] += 1
                    
            except Exception as e:
                error_msg = str(e)[:50]
                print(f"      ‚ùå {class_name}: {error_msg}")
                results[class_name] = f'ERROR: {error_msg}'
                self.stats['failed_tests'] += 1
        
        # Guardar resultados
        if 'multi_product' not in self.results:
            self.results['multi_product'] = {}
        self.results['multi_product']['etf_trick'] = {
            'tested_functions': len(functions),
            'tested_classes': len(classes),
            'results': results,
            'input_shape': underlying_prices.shape
        }
    
    def _validate_futures_roll(self, module):
        """
        Validar m√≥dulo futures_roll con argumentos correctos
        """
        sample_data = self._get_sample_price_data()
        if sample_data is None:
            print("      ‚ö†Ô∏è No hay datos apropiados para testing")
            return
        
        functions = [name for name in dir(module) if any(x in name.lower() for x in ['roll', 'future', 'contract'])]
        classes = [name for name in dir(module) if name[0].isupper() and hasattr(getattr(module, name), '__call__')]
        
        if functions:
            item = getattr(module, functions[0])
            print(f"      üß™ Testing {functions[0]}...")
            try:
                if hasattr(item, '__call__') and not hasattr(item, '__init__'):
                    # Es una funci√≥n
                    result = item(sample_data.head(50))
                    print(f"      ‚úÖ Futures roll function: {len(result) if hasattr(result, '__len__') else 'Calculado'}")
                else:
                    # Es una clase 
                    print(f"      ‚ö†Ô∏è Clase {functions[0]} requiere par√°metros espec√≠ficos de contratos futuros")
                    print(f"      ‚úÖ Clase {functions[0]} disponible para uso avanzado")
            except Exception as e:
                print(f"      ‚ö†Ô∏è {str(e)[:80]}...")
    
    # ========================================================================
    # FUNCIONES AUXILIARES COMPLETAS - COMPLETADO
    # ========================================================================
    
    def _print_final_summary(self) -> None:
        """Imprimir resumen final de la validaci√≥n"""
        elapsed_time = time.time() - self.start_time
        
        print("\n" + "=" * 80)
        print("üéØ RESUMEN FINAL DE VALIDACI√ìN")
        print("=" * 80)
        print(f"‚è±Ô∏è Tiempo total: {elapsed_time:.1f} segundos")
        print(f"üìä Datasets procesados: {len(self.data_sources)}")
        print(f"üì¶ M√≥dulos validados: {sum(len(m) for m in self.modules.values())}")
        
        # Verificar si tenemos stats
        if hasattr(self, 'stats'):
            print(f"‚úÖ Tests pasados: {self.stats.get('passed_tests', 0)}")
            print(f"‚ùå Tests fallidos: {self.stats.get('failed_tests', 0)}")
        
        print(f"‚ö†Ô∏è Errores encontrados: {len(self.errors)}")
        
        if self.errors:
            print(f"\nüö® ERRORES DETECTADOS:")
            for i, error in enumerate(self.errors[:10], 1):
                print(f"   {i}. {error}")
            
            if len(self.errors) > 10:
                print(f"   ... y {len(self.errors) - 10} errores m√°s")
        
        print(f"\nüìÖ Finalizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
    
    def _generate_comprehensive_report(self) -> None:
        """Generar reporte comprehensivo de la validaci√≥n"""
        print("\nüìÑ GENERANDO REPORTE COMPREHENSIVE...")
        
        # Crear reporte b√°sico
        report_file = f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(report_file, 'w') as f:
            f.write("REPORTE DE VALIDACI√ìN L√ìPEZ DE PRADO\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Datasets cargados: {len(self.data_sources)}\n")
            f.write(f"M√≥dulos validados: {sum(len(m) for m in self.modules.values())}\n")
            f.write(f"Errores encontrados: {len(self.errors)}\n\n")
            
            if self.errors:
                f.write("ERRORES DETECTADOS:\n")
                f.write("-" * 20 + "\n")
                for i, error in enumerate(self.errors, 1):
                    f.write(f"{i}. {error}\n")
        
        print(f"      ‚úÖ Reporte guardado en: {report_file}")
    
    def _create_professional_visualizations(self) -> None:
        """Crear visualizaciones profesionales de los resultados"""
        print("\nüìä CREANDO VISUALIZACIONES PROFESIONALES...")
        
        try:
            import matplotlib.pyplot as plt
            
            # Crear gr√°fico simple de resumen
            fig, ax = plt.subplots(figsize=(10, 6))
            
            categories = list(self.modules.keys())
            counts = [len(self.modules[cat]) for cat in categories]
            
            ax.bar(categories, counts)
            ax.set_title('M√≥dulos Cargados por Categor√≠a')
            ax.set_ylabel('N√∫mero de M√≥dulos')
            
            plot_file = f"validation_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(plot_file)
            plt.close()
            
            print(f"      ‚úÖ Gr√°fico guardado en: {plot_file}")
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è No se pudieron crear visualizaciones: {str(e)}")
    
    def _save_error_state(self, error: Exception) -> None:
        """Guardar estado de error para debugging"""
        error_file = f"validation_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        with open(error_file, 'w') as f:
            f.write(f"Error de validaci√≥n: {datetime.now()}\n")
            f.write(f"Error: {str(error)}\n\n")
            f.write("Traceback:\n")
            f.write(traceback.format_exc())
            f.write(f"\nEstado del validador:\n")
            f.write(f"M√≥dulos cargados: {sum(len(m) for m in self.modules.values())}\n")
            f.write(f"Datasets cargados: {len(self.data_sources)}\n")
            f.write(f"Errores previos: {len(self.errors)}\n")
        
        print(f"üíæ Estado de error guardado en: {error_file}")
    
    def _get_sample_tick_data(self) -> Optional[pd.DataFrame]:
        """Obtener datos de tick apropiados para testing"""
        print("      üîç Buscando datos de alta frecuencia...")
        
        # Priorizar datos de WTI 1 minuto (el m√°s completo)
        wti_keys = [k for k in self.data_sources.keys() if 'wti' in k.lower() and '1_min' in k]
        
        if wti_keys:
            key = wti_keys[0]
            data = self.data_sources[key]
            print(f"      ‚úÖ Usando datos WTI: {key}")
            
            # Convertir a formato esperado [date_time, price, volume]
            if len(data) > 10:
                result_data = pd.DataFrame()
                
                # Buscar columnas de precio y volumen
                price_cols = [col for col in data.columns if any(p in col.lower() for p in ['price', 'close', 'last'])]
                volume_cols = [col for col in data.columns if 'volume' in col.lower()]
                
                if price_cols:
                    result_data['price'] = data[price_cols[0]]
                if volume_cols:
                    result_data['volume'] = data[volume_cols[0]]
                elif len(data.columns) > 1:
                    result_data['volume'] = data.iloc[:, 1]  # Segunda columna como volumen
                else:
                    result_data['volume'] = 1000  # Volumen constante
                
                # Agregar timestamp
                if isinstance(data.index, pd.DatetimeIndex):
                    result_data.index = data.index
                else:
                    result_data.index = pd.date_range('2020-01-01', periods=len(result_data), freq='1min')
                
                return result_data.dropna()
        
        # Fallback: usar datos sint√©ticos
        if 'synthetic_tick_data' in self.data_sources:
            print("      ‚úÖ Usando datos sint√©ticos de tick")
            return self.data_sources['synthetic_tick_data']
        
        print("      ‚ö†Ô∏è No se encontraron datos de tick apropiados")
        return None
    
    def _get_sample_price_data(self) -> Optional[pd.Series]:
        """Obtener datos de precios apropiados para labeling"""
        print("      üîç Buscando datos de precios para labeling...")
        
        # Priorizar datos diarios de Tiingo (m√°s limpios)
        tiingo_keys = [k for k in self.data_sources.keys() if 'tiingo' in k and 'daily' in k]
        
        if tiingo_keys:
            key = tiingo_keys[0]
            data = self.data_sources[key]
            
            # Buscar columna de precio de cierre
            price_cols = [col for col in data.columns if any(p in col.lower() for p in ['close', 'price'])]
            if price_cols and len(data) > 100:
                prices = data[price_cols[0]].dropna()
                print(f"      ‚úÖ Usando precios Tiingo: {key} ({len(prices)} puntos)")
                return prices
        
        # Fallback: datos de yfinance
        yf_keys = [k for k in self.data_sources.keys() if 'yfinance' in k]
        if yf_keys:
            key = yf_keys[0]
            data = self.data_sources[key]
            if 'close' in data.columns and len(data) > 50:
                prices = data['close'].dropna()
                print(f"      ‚úÖ Usando precios yfinance: {key} ({len(prices)} puntos)")
                return prices
        
        print("      ‚ö†Ô∏è No se encontraron datos de precios apropiados")
        return None

# ========================================================================
# FUNCI√ìN PRINCIPAL Y EJECUCI√ìN
# ========================================================================

def main():
    """Funci√≥n principal de validaci√≥n"""
    try:
        print("üöÄ INICIANDO VALIDADOR L√ìPEZ DE PRADO")
        print("=" * 50)
        
        # Crear instancia del validador
        validator = LopezDePradoValidator()
        
        # Ejecutar validaci√≥n completa
        validator.run_complete_validation()
        
        return validator
        
    except Exception as e:
        print(f"\nüí• ERROR CR√çTICO:")
        print(f"   {str(e)}")
        traceback.print_exc()
        return None

if __name__ == "__main__":
    validator = main()
    
    if validator:
        print("\n‚úÖ VALIDACI√ìN COMPLETADA EXITOSAMENTE")
    else:
        print("\n‚ùå VALIDACI√ìN FALLIDA")
    
    print("=" * 50)